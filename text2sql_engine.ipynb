{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from sqlglot import parse_one\n",
    "\n",
    "from APIKEY import APIKEY\n",
    "from systemidentity import identity\n",
    "\n",
    "import sqlite3\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=APIKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_names = ['sqlite_db/books.sqlite',\n",
    "            'sqlite_db/disney.sqlite',\n",
    "            'sqlite_db/genes.sqlite',\n",
    "            'sqlite_db/movie_platform.sqlite',\n",
    "            'sqlite_db/shipping.sqlite']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Extract column names from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_mapping(db_file):\n",
    "    # print(f\"Executing get_column_mapping function for file {db_file} \")\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "\n",
    "    column_mapping = {}\n",
    "\n",
    "    for table in tables:\n",
    "        table_name = table[0]\n",
    "        cursor.execute(f'PRAGMA table_info(\"{table_name}\");')\n",
    "        columns = cursor.fetchall()\n",
    "        column_mapping[table_name] = [column[1] for column in columns]\n",
    "\n",
    "    conn.close()\n",
    "    return column_mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Generate the SQL Query using OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_tosql(question: str, column_mapping) -> str:\n",
    "\n",
    "    # print(f\"Executing text_tosql function for {question} \")\n",
    "\n",
    "    schema_context = \"\"\n",
    "    for table, columns in column_mapping.items():\n",
    "        schema_context += f\"Table: {table}\\nColumns: {', '.join(columns)}\\n\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following database schema: {schema_context}\n",
    "    Translate this into an SQL query: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": identity },\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    sql_query = (response.choices[0].message.content).strip()\n",
    "    return sql_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Validate with sqlglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_sql(sql_query):\n",
    "    try:\n",
    "        parsed = parse_one(sql_query)\n",
    "        return (f\"VALID QUERY --> {parsed.sql()}\"), parsed.sql()\n",
    "    except Exception as e:\n",
    "        return (f'Error  {str(e)}'), None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iteration Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract db_id from the file path\n",
    "def get_db_id(file_path):\n",
    "    return file_path.split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to add and update the LLM_SQL column in the CSV\n",
    "\n",
    "def update_csv_with_llm_sql(output_file, question, generated_sql):\n",
    "    updated_rows = []\n",
    "\n",
    "    with open(output_file, mode='r', newline='') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        fieldnames = reader.fieldnames\n",
    "        \n",
    "        if 'LLM_SQL' not in fieldnames:\n",
    "            fieldnames.append('LLM_SQL')\n",
    "        \n",
    "        for row in reader:\n",
    "            if row['question'].strip() == question.strip():\n",
    "                row['LLM_SQL'] = generated_sql\n",
    "            updated_rows.append(row)\n",
    "\n",
    "    with open(output_file, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(updated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV data and create a dictionary of questions for each db_id\n",
    "questions_by_db = {}\n",
    "file_csv = 'output_30.csv' #30 random questions for testing\n",
    "\n",
    "with open(file_csv, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        db_id = row['db_id']\n",
    "        question = row['question']\n",
    "        if db_id not in questions_by_db:\n",
    "            questions_by_db[db_id] = []\n",
    "        questions_by_db[db_id].append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For sqlite_db/books.sqlite\n",
      "For books\n",
      "For Among the books published by publisher ID 1929, how many of them have over 500 pages?\n",
      "For Which customer has made the most orders? Show his/her full name.\n",
      "For What is the average number of pages of David Coward's books?\n",
      "For Among Daisey Lamball's orders, how many were shipped via International shipping?\n",
      "For What is the full name of the customer who ordered the most books of all time?\n",
      "For In books published by Ace Book, what is the percentage of English books published?\n",
      "For sqlite_db/disney.sqlite\n",
      "For disney\n",
      "For How much more total box office gross did the Walt Disney Company have in revenue in 1998 than in 1997?\n",
      "For Which song is associated with the most popular Disney movie in 1970s?\n",
      "For Name the first movie released by Disney.\n",
      "For How many movies were released by Disney between 2010 and 2016?\n",
      "For Name the top 5 highest-grossing Disney movies adjusted for inflation. Identify the percentage they contributed to the total of Disney's current gross.\n",
      "For Among all Disney movies directed by Gary Trousdale, determine the percentage that earned over USD100m based on actual grossing.\n",
      "For sqlite_db/genes.sqlite\n",
      "For genes\n",
      "For For the genes that are located in the plasma membrane, please list their number of chromosomes.\n",
      "For Among the genes with nucleic acid metabolism defects, how many of them can be found in the vacuole?\n",
      "For Please list the motif of the genes that are located in the cytoplasm and have 7 chromosomes.\n",
      "For For the non-essential genes whose functions are transcription, how many of them are not located in the cytoplasm?\n",
      "For For the pairs of genes both from the class ATPases, what is the average expression correlation score?\n",
      "For What percentage of genes located in the cytoskeleton are of unknown class? And of these, how many are not conditional phenotypes?\n",
      "For sqlite_db/movie_platform.sqlite\n",
      "For movie_platform\n",
      "For What is the name of the longest movie title? When was it released?\n",
      "For What is the average number of Mubi users who love movies directed by Stanley Kubrick?\n",
      "For What is the average rating for movie titled 'When Will I Be Loved'?\n",
      "For Who is the director of the movie Sex, Drink and Bloodshed?\n",
      "For How many users, who were a paying subscriber when they rated the movie, gave the movie that was released in 1924 and directed by Erich von Stroheim a rating score of 5?\n",
      "For What is the average number of movies added to the lists of user 8516503? Give the user profile image URL on Mubi.\n",
      "For sqlite_db/shipping.sqlite\n",
      "For shipping\n",
      "For How many shipments were ordered by S K L Enterprises Inc in 2017?\n",
      "For How many shipments in 2017 were done by Sue Newell?\n",
      "For Tell the name of the driver who received the shipment on 2017/11/5.\n",
      "For What is the average shipment weight carried by the oldest Mack?\n",
      "For What is the first name of the driver who transported shipment id 1028?\n",
      "For Give the full name of driver who transported the items on 3/2/2016.\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the database files\n",
    "for dbfile in db_names:\n",
    "    print(f\"For {dbfile}\")\n",
    "    column_mapping = get_column_mapping(db_file=dbfile) #Step 1\n",
    "    db_id = get_db_id(dbfile)\n",
    "\n",
    "    if db_id in questions_by_db:\n",
    "        print(f\"For {db_id}\")\n",
    "        questions = questions_by_db[db_id]\n",
    "        for question in questions:\n",
    "            print(f\"For {question}\")\n",
    "            sql_query = text_tosql(question, column_mapping)  # Step 2\n",
    "            validation_result, validsql = validate_sql(sql_query=sql_query)\n",
    "            if \"VALID QUERY\" in validation_result:\n",
    "                update_csv_with_llm_sql(file_csv, question, validsql)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
